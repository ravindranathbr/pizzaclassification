{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.layers import Activation, Dropout, Flatten, Dense\n",
    "from keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "\n",
    "import cv2                 # working with, mainly resizing, images\n",
    "import numpy as np\n",
    "import os\n",
    "from random import shuffle # randomizing ordered data\n",
    "from tqdm import tqdm      # a nice pretty percentage bar for tasks.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# define variables \n",
    "\n",
    "TRAIN_DIR = 'data/train'\n",
    "TEST_DIR = 'data/test'\n",
    "IMG_WIDTH, IMG_HEIGHT = 100, 100 # dimensions of our images.\n",
    "LR = 1e-3\n",
    "\n",
    "MODEL_NAME = 'pizzas-{}-{}.model'.format(LR, '2conv-basic') # just so we remember which saved model is which, sizes must match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# One hot encoding of the target colum\n",
    "def label_img(img, word_label):\n",
    "    if word_label == 'Pepperoni': return [1,0]\n",
    "    elif word_label == 'Sausage': return [0,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Create training data\n",
    "def create_train_data(directory='', label='', num_of_images=1000):\n",
    "    training_data = []\n",
    "    if directory=='':\n",
    "        directory = TRAIN_DIR\n",
    "    label_dir = directory+'/'+label\n",
    "    i=0\n",
    "    for img in tqdm(os.listdir(label_dir)):\n",
    "        img_label = label_img(img, label)\n",
    "        path = os.path.join(label_dir,img)\n",
    "        img = cv2.imread(path,cv2.IMREAD_GRAYSCALE)\n",
    "        img = cv2.resize(img, (IMG_WIDTH, IMG_HEIGHT))\n",
    "        training_data.append([np.array(img),np.array(img_label)])\n",
    "        i=i+1\n",
    "        if i>num_of_images:\n",
    "            break\n",
    "    return training_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_data_Pepperoni = create_train_data('Pepperoni')\n",
    "train_data_Sausage = create_train_data('Sausage')\n",
    "train_data = train_data_Pepperoni.append(train_data_Sausage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_data = train_data_Pepperoni"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "shuffle(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.save('data/train_data.npy', train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "shuffle(training_data)\n",
    "np.save('data/train_data.npy', training_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Augumentation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define the data generation object\n",
    "datagen = ImageDataGenerator(\n",
    "        rotation_range=40,\n",
    "        width_shift_range=0.4,\n",
    "        height_shift_range=0.4,\n",
    "        shear_range=0.25,\n",
    "        zoom_range=0.25,\n",
    "        rescale=1.01,\n",
    "        zca_epsilon=1e-6,\n",
    "        horizontal_flip=True,\n",
    "        fill_mode='nearest')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "string=\"data/new_train/Pepperoni/._0_9746.jpeg\"\n",
    "print (string[0:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Function to generate images\n",
    "def augument_images(source_dir_name, dest_dir_name, num_images):\n",
    "    for image in tqdm(os.listdir(source_dir_name)):\n",
    "        img = load_img(source_dir_name+'/'+image)\n",
    "        x = img_to_array(img)  # this is a Numpy array with shape (3, 150, 150)\n",
    "        x = x.reshape((1,) + x.shape)  # this is a Numpy array with shape (1, 3, 150, 150)\n",
    "        # the .flow() command below generates batches of randomly transformed images\n",
    "        # and saves the results to the `preview/` directory\n",
    "        i = 0\n",
    "        image_name = image[0:-4]\n",
    "        for batch in datagen.flow(x, batch_size=1,\n",
    "                          save_to_dir=dest_dir_name, save_prefix=image_name, save_format='jpeg'):\n",
    "            i += 1\n",
    "            if i > num_images:\n",
    "                break  # otherwise the generator would loop indefinitely\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#source_dir_name = '/home/datascience/projects/vsoft/data/test'\n",
    "pepperoni_source_dir_name = '/home/datascience/projects/vsoft/data/train/Pepperoni'\n",
    "pepperoni_dest_dir_name = 'data/new_train/Pepperoni/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "augument_images(pepperoni_source_dir_name, pepperoni_dest_dir_name, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#source_dir_name = '/home/datascience/projects/vsoft/data/test'\n",
    "sausage_source_dir_name = '/home/datascience/projects/vsoft/data/train/Sausage'\n",
    "sausage_dest_dir_name = '/home/datascience/projects/vsoft/data/new_train/Sausage'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "augument_images(sausage_source_dir_name,sausage_dest_dir_name,10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preperation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "source_dir_name = '/home/datascience/projects/vsoft/data/new_train'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pepperoni_data = create_train_data(source_dir_name,'Pepperoni',1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sausage_data = create_train_data(source_dir_name,'Sausage',1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save data for later use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.save('data/pepperoni_data.npy', pepperoni_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.save('data/sausage_data.npy', sausage_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Segregate the data into train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pepperoni_data = np.load('data/sausage_data.npy')\n",
    "sausage_data = np.load('data/sausage_data.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "full_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "full_data = np.concatenate((pepperoni_data, sausage_data), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "shuffle(full_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train = full_data[:-1600]\n",
    "test = full_data[-400:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.array(train).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X=[]\n",
    "Y=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for i in train:\n",
    "    #print(i[0])\n",
    "    #print(len(i))\n",
    "    X.append(i[0].reshape(IMG_WIDTH, IMG_HEIGHT,1))\n",
    "    Y.append(i[1])\n",
    "    #print(i[0].reshape(IMG_WIDTH, IMG_HEIGHT,1).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.array(X).shape\n",
    "np.array(Y).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X= np.array(X)\n",
    "Y= np.array(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_test=[]\n",
    "Y_test=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for i in test:\n",
    "    #print(i[0])\n",
    "    #print(len(i))\n",
    "    X_test.append(i[0].reshape(IMG_WIDTH, IMG_HEIGHT,1))\n",
    "    #print(i[0].reshape(IMG_WIDTH, IMG_HEIGHT,1).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.array(X_test).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_test = np.array(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X = np.array([i[0] for i in train[0:600]]).reshape(-1,IMG_WIDTH,IMG_HEIGHT,1)\n",
    "Y = np.array([i[1] for i in train[0:600]])\n",
    "\n",
    "test_x = np.array([i[0] for i in test[0:90]]).reshape(-1,IMG_WIDTH,IMG_HEIGHT,1)\n",
    "test_y = [i[1] for i in test[0:90]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolution Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.layers import Activation, Dropout, Flatten, Dense\n",
    "from keras import backend as K\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "K.clear_session()\n",
    "sess = tf.Session()\n",
    "K.set_session(sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Define variables\n",
    "nb_train_samples = 2000\n",
    "nb_validation_samples = 800\n",
    "epochs = 50\n",
    "batch_size = 16\n",
    "num_classes = 2\n",
    "\n",
    "if K.image_data_format() == 'channels_first':\n",
    "    input_shape = (1, IMG_WIDTH, IMG_HEIGHT) # For RGB, (3, IMG_WIDTH, IMG_HEIGHT) \n",
    "else:\n",
    "    input_shape = (IMG_WIDTH, IMG_HEIGHT, 1) # For RGB, (IMG_WIDTH, IMG_HEIGHT, 3) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# GPU DEFAULT\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, kernel_size=(5, 5), strides=(1, 1),\n",
    "                 activation='relu',\n",
    "                 input_shape=input_shape))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "model.add(Conv2D(64, (5, 5), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(100, activation='relu'))\n",
    "model.add(Dense(num_classes, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# CPU Code\n",
    "with tf.device('/cpu:0'):\n",
    "    #x = tf.placeholder(tf.float32, shape=(None, 784))\n",
    "    # shared model living on CPU:0\n",
    "    # it won't actually be run during training; it acts as an op template\n",
    "    # and as a repository for shared variables\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(32, kernel_size=(5, 5), strides=(1, 1),\n",
    "                 activation='relu',\n",
    "                 input_shape=input_shape))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "    model.add(Conv2D(64, (5, 5), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(100, activation='relu'))\n",
    "    model.add(Dense(num_classes, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "model.compile('adam', 'categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Fit the model\n",
    "history = model.fit(X, Y, verbose=0, epochs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
