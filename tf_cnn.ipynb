{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.contrib import learn\n",
    "from tensorflow.contrib import layers\n",
    "from tensorflow.contrib import losses\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "from sklearn import metrics\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from random import shuffle # randomizing ordered data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "IMG_WIDTH, IMG_HEIGHT = 100, 100 # dimensions of our images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Set logging level to info to see detailed log output\n",
    "tf.logging.set_verbosity(tf.logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pepperoni_data = np.load('data/pepperoni_rgb_data.npy')\n",
    "sausage_data = np.load('data/sausage_rgb_data.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pepperoni_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sausage_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "full_data = np.concatenate((pepperoni_data, sausage_data), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "full_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "shuffle(full_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Segregate the data into training, validation and test sets\n",
    "train = full_data[0:1500]\n",
    "validation = full_data[1501:1750]\n",
    "test = full_data[-250:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# For Gray Scale Images\n",
    "X_train = np.array([i[0] for i in train], dtype='f').reshape(-1,IMG_WIDTH,IMG_HEIGHT,1)\n",
    "y_train = np.array([i[1] for i in train], dtype='int32')\n",
    "\n",
    "X_validation = np.array([i[0] for i in validation], dtype='f').reshape(-1,IMG_WIDTH,IMG_HEIGHT,1)\n",
    "y_validation = np.array([i[1] for i in validation], dtype='int32')\n",
    "\n",
    "X_test = np.array([i[0] for i in test], dtype='f').reshape(-1, IMG_WIDTH, IMG_HEIGHT, 1)\n",
    "y_test = np.array([i[1] for i in test], dtype='int32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# For RGB, 3 channel layout\n",
    "X_train = np.array([i[0] for i in train], dtype='f').reshape(-1,IMG_WIDTH,IMG_HEIGHT,3)\n",
    "y_train = np.array([i[1] for i in train], dtype='int32')\n",
    "\n",
    "X_validation = np.array([i[0] for i in validation], dtype='f').reshape(-1,IMG_WIDTH,IMG_HEIGHT,3)\n",
    "y_validation = np.array([i[1] for i in validation], dtype='int32')\n",
    "\n",
    "X_test = np.array([i[0] for i in test], dtype='f').reshape(-1, IMG_WIDTH, IMG_HEIGHT, 3)\n",
    "y_test = np.array([i[1] for i in test], dtype='int32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# creating custom estimator\n",
    "def model_function_2d(features, targets, mode):\n",
    "    #input layer \n",
    "    #Reshape features to 4-D tensor: [batch_size, width, height, channels]\n",
    "    # MNIST images are 28x28 pixels, and have one color channel \n",
    "    #batch_size corresponds to number of images: -1 represents compute the number of images automatically\n",
    "    input_layer = tf.reshape(features, [-1, IMG_WIDTH, IMG_HEIGHT, 1])\n",
    "    kernel_size_1=[5, 5, 5]\n",
    "    \n",
    "    # Convolutional Layer #1\n",
    "    # Computes 32 features using a 5x5 filter with ReLU activation.\n",
    "    # Padding is added to preserve width and height.\n",
    "    # Input Tensor Shape: [batch_size, 28, 28, 1]\n",
    "    # Output Tensor Shape: [batch_size, 28, 28, 32]\n",
    "    conv1 = tf.layers.conv3d(\n",
    "      inputs=input_layer,\n",
    "      num_of_outputs=32,\n",
    "      kernel_size=kernel_size_1,\n",
    "      stride=1,\n",
    "      padding=\"SAME\",\n",
    "      activation_fn=tf.nn.relu)\n",
    "    \n",
    "    # Pooling Layer #1\n",
    "    # First max pooling layer with a 2x2 filter and stride of 2\n",
    "    # Input Tensor Shape: [batch_size, 28, 28, 32]\n",
    "    # Output Tensor Shape: [batch_size, 14, 14, 32]\n",
    "    pool1 = layers.max_pool2d(inputs=conv1, kernel_size=[2, 2], stride=2)\n",
    "    \n",
    "    # Convolutional Layer #2\n",
    "    # Computes 64 features using a 5x5 filter.\n",
    "    # Padding is added to preserve width and height.\n",
    "    # Input Tensor Shape: [batch_size, 14, 14, 32]\n",
    "    # Output Tensor Shape: [batch_size, 14, 14, 64]\n",
    "    conv2 = layers.conv2d(\n",
    "      inputs=pool1,\n",
    "      num_outputs=64,\n",
    "      kernel_size=[5, 5],\n",
    "      stride=1,\n",
    "      padding=\"SAME\",\n",
    "      activation_fn=tf.nn.relu)\n",
    "    # Pooling Layer #2\n",
    "    # Second max pooling layer with a 2x2 filter and stride of 2\n",
    "    # Input Tensor Shape: [batch_size, 14, 14, 64]\n",
    "    # Output Tensor Shape: [batch_size, 7, 7, 64]\n",
    "    pool2 = layers.max_pool2d(inputs=conv2, kernel_size=[2, 2], stride=2)\n",
    "    \n",
    "    # Flatten tensor into a batch of vectors\n",
    "    # Input Tensor Shape: [batch_size, 7, 7, 64]\n",
    "    # Output Tensor Shape: [batch_size, 7 * 7 * 64]\n",
    "    \n",
    "    pool2_flat = tf.reshape(pool2, [-1, int(IMG_WIDTH/4) * int(IMG_HEIGHT/4) * 64])\n",
    "    \n",
    "    # Fully connected Layers with 100, 20 neurons\n",
    "    # Input Tensor Shapuntitled0.e: [batch_size, 14 * 14 * 32]\n",
    "    # Output Tensor Shape: [batch_size, 10]\n",
    "    fclayers = layers.stack(pool2_flat, layers.fully_connected, [100,20], activation_fn = tf.nn.relu)\n",
    "    outputs = layers.fully_connected(inputs=fclayers,\n",
    "                                                 num_outputs=2,\n",
    "                                                 activation_fn=None)\n",
    "    # Calculate loss using mean squared error\n",
    "    loss = losses.softmax_cross_entropy(outputs, targets)\n",
    "    # Create an optimizer for minimizing the loss function\n",
    "    optimizer = layers.optimize_loss(\n",
    "      loss=loss,\n",
    "      global_step=tf.contrib.framework.get_global_step(),\n",
    "      learning_rate=0.8,\n",
    "      optimizer=\"SGD\")\n",
    "    probs = tf.nn.softmax(outputs)\n",
    "    \n",
    "    return {'probs':probs, 'labels':tf.arg_max(probs,1)}, loss, optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# For VIDEOS\n",
    "# creating custom estimator\n",
    "def model_function_3d_for_videos(features, targets, mode):\n",
    "    #input layer \n",
    "    #Reshape features to 4-D tensor: [batch_size, width, height, channels]\n",
    "    # MNIST images are 28x28 pixels, and have one color channel \n",
    "    #batch_size corresponds to number of images: -1 represents compute the number of images automatically\n",
    "    input_layer = tf.reshape(features, [-1, IMG_WIDTH, IMG_HEIGHT, 3])\n",
    "    kernel_size_1 = [5, 5, 5]\n",
    "    kernel_size_2 = [5, 5, 5]\n",
    "    \n",
    "    # Convolutional Layer #1\n",
    "    # Computes 32 features using a 5x5 filter with ReLU activation.\n",
    "    # Padding is added to preserve width and height.\n",
    "    # Input Tensor Shape: [batch_size, 28, 28, 1]\n",
    "    # Output Tensor Shape: [batch_size, 28, 28, 32]\n",
    "    conv1 = tf.layers.conv3d(\n",
    "      inputs=input_layer,\n",
    "      filters=32,\n",
    "      kernel_size=kernel_size_1,\n",
    "      strides=(1,1,1),\n",
    "      padding=\"SAME\",\n",
    "      activation=tf.nn.relu)\n",
    "    \n",
    "    # Pooling Layer #1\n",
    "    # First max pooling layer with a 2x2 filter and stride of 2\n",
    "    # Input Tensor Shape: [batch_size, 28, 28, 32]\n",
    "    # Output Tensor Shape: [batch_size, 14, 14, 32]\n",
    "    pool1 = tf.layers.max_pooling3d(inputs=conv1, pool_size=[2, 2, 2], strides=(2,2,2))\n",
    "    \n",
    "    # Convolutional Layer #2\n",
    "    # Computes 64 features using a 5x5 filter.\n",
    "    # Padding is added to preserve width and height.\n",
    "    # Input Tensor Shape: [batch_size, 14, 14, 32]\n",
    "    # Output Tensor Shape: [batch_size, 14, 14, 64]\n",
    "    conv2 = tf.layers.conv3d(\n",
    "      inputs=pool1,\n",
    "      num_outputs=64,\n",
    "      kernel_size=kernel_size_2,\n",
    "      strides=(1,1,1),\n",
    "      padding=\"SAME\",\n",
    "      activation_fn=tf.nn.relu)\n",
    "    # Pooling Layer #2\n",
    "    # Second max pooling layer with a 2x2 filter and stride of 2\n",
    "    # Input Tensor Shape: [batch_size, 14, 14, 64]\n",
    "    # Output Tensor Shape: [batch_size, 7, 7, 64]\n",
    "    pool2 = tf.layers.max_pooling3d(inputs=conv2, pool_size=[2, 2, 2], strides=(2,2,2))\n",
    "    \n",
    "    # Flatten tensor into a batch of vectors\n",
    "    # Input Tensor Shape: [batch_size, 7, 7, 64]\n",
    "    # Output Tensor Shape: [batch_size, 7 * 7 * 64]\n",
    "    \n",
    "    pool2_flat = tf.reshape(pool2, [-1, int(IMG_WIDTH/4) * int(IMG_HEIGHT/4) * 64 * 3])\n",
    "    \n",
    "    # Fully connected Layers with 100, 20 neurons\n",
    "    # Input Tensor Shapuntitled0.e: [batch_size, 14 * 14 * 32]\n",
    "    # Output Tensor Shape: [batch_size, 10]\n",
    "    fclayers = layers.stack(pool2_flat, layers.fully_connected, [100,20], activation_fn = tf.nn.relu)\n",
    "    outputs = layers.fully_connected(inputs=fclayers,\n",
    "                                                 num_outputs=2,\n",
    "                                                 activation_fn=None)\n",
    "    # Calculate loss using mean squared error\n",
    "    loss = losses.softmax_cross_entropy(outputs, targets)\n",
    "    # Create an optimizer for minimizing the loss function\n",
    "    optimizer = layers.optimize_loss(\n",
    "      loss=loss,\n",
    "      global_step=tf.contrib.framework.get_global_step(),\n",
    "      learning_rate=0.8,\n",
    "      optimizer=\"SGD\")\n",
    "    probs = tf.nn.softmax(outputs)\n",
    "    \n",
    "    return {'probs':probs, 'labels':tf.arg_max(probs,1)}, loss, optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# For Images\n",
    "# creating custom estimator\n",
    "def model_function(features, targets, mode):\n",
    "    #input layer \n",
    "    #Reshape features to 4-D tensor: [batch_size, width, height, channels]\n",
    "    # MNIST images are 28x28 pixels, and have one color channel \n",
    "    #batch_size corresponds to number of images: -1 represents compute the number of images automatically\n",
    "    input_layer = tf.reshape(features, [-1, IMG_WIDTH, IMG_HEIGHT, 1])\n",
    "    kernel_size_1=[3, 3]\n",
    "    \n",
    "    # Convolutional Layer #1\n",
    "    # Computes 32 features using a 5x5 filter with ReLU activation.\n",
    "    # Padding is added to preserve width and height.\n",
    "    # Input Tensor Shape: [batch_size, 28, 28, 1]\n",
    "    # Output Tensor Shape: [batch_size, 28, 28, 32]\n",
    "    conv1 = layers.conv2d(\n",
    "      inputs=input_layer,\n",
    "      num_outputs=32,\n",
    "      kernel_size=kernel_size_1,\n",
    "      stride=1,\n",
    "      padding=\"SAME\",\n",
    "      activation_fn=tf.nn.relu)\n",
    "    \n",
    "    # Pooling Layer #1\n",
    "    # First max pooling layer with a 2x2 filter and stride of 2\n",
    "    # Input Tensor Shape: [batch_size, 28, 28, 32]\n",
    "    # Output Tensor Shape: [batch_size, 14, 14, 32]\n",
    "    pool1 = layers.max_pool2d(inputs=conv1, kernel_size=[2, 2], stride=2)\n",
    "    \n",
    "    # Convolutional Layer #2\n",
    "    # Computes 64 features using a 5x5 filter.\n",
    "    # Padding is added to preserve width and height.\n",
    "    # Input Tensor Shape: [batch_size, 14, 14, 32]\n",
    "    # Output Tensor Shape: [batch_size, 14, 14, 64]\n",
    "    conv2 = layers.conv2d(\n",
    "      inputs=pool1,\n",
    "      num_outputs=64,\n",
    "      kernel_size=[2, 2],\n",
    "      stride=1,\n",
    "      padding=\"SAME\",\n",
    "      activation_fn=tf.nn.relu)\n",
    "    # Pooling Layer #2\n",
    "    # Second max pooling layer with a 2x2 filter and stride of 2\n",
    "    # Input Tensor Shape: [batch_size, 14, 14, 64]\n",
    "    # Output Tensor Shape: [batch_size, 7, 7, 64]\n",
    "    pool2 = layers.max_pool2d(inputs=conv2, kernel_size=[2, 2], stride=2)\n",
    "    \n",
    "    # Flatten tensor into a batch of vectors\n",
    "    # Input Tensor Shape: [batch_size, 7, 7, 64]\n",
    "    # Output Tensor Shape: [batch_size, 7 * 7 * 64]\n",
    "    \n",
    "    pool2_flat = tf.reshape(pool2, [-1, int(IMG_WIDTH/4) * int(IMG_HEIGHT/4) * 64 * 3 ])\n",
    "    \n",
    "    # Fully connected Layers with 100, 20 neurons\n",
    "    # Input Tensor Shapuntitled0.e: [batch_size, 14 * 14 * 32]\n",
    "    # Output Tensor Shape: [batch_size, 10]\n",
    "    fclayers = layers.stack(pool2_flat, layers.fully_connected, [200,40], activation_fn = tf.nn.relu)\n",
    "    outputs = layers.fully_connected(inputs=fclayers,\n",
    "                                                 num_outputs=2,\n",
    "                                                 activation_fn=None)\n",
    "    # Calculate loss using mean squared error\n",
    "    loss = losses.sigmoid_cross_entropy(outputs, targets)\n",
    "    # Create an optimizer for minimizing the loss function\n",
    "    optimizer = layers.optimize_loss(\n",
    "      loss=loss,\n",
    "      global_step=tf.contrib.framework.get_global_step(),\n",
    "      learning_rate=0.1,\n",
    "      optimizer=\"SGD\")\n",
    "    probs = tf.nn.softmax(outputs)\n",
    "    \n",
    "    return {'probs':probs, 'labels':tf.arg_max(probs,1)}, loss, optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#create custom estimator\n",
    "nn = learn.Estimator(model_fn=model_function, model_dir=\"/home/datascience/projects/vsoft/tf_model_new\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#build the model\n",
    "nn.fit(x=X_train, y=y_train, steps=100, batch_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for var in nn.get_variable_names():\n",
    "    print (\"%s:%s\" % (var,nn.get_variable_value(var)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Predict the outcome of test data using model\n",
    "predictions = nn.predict(X_test, as_iterable=True)\n",
    "y_pred = []\n",
    "for i, p in enumerate(predictions):\n",
    "    y_pred.append(p['labels'])\n",
    "    print(\"Prediction %s: %s : %s\" % (i + 1, p['probs'], p['labels']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "score = metrics.accuracy_score(np.argmax(y_test,1), y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preperation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "\n",
    "import cv2                 # working with, mainly resizing, images\n",
    "import numpy as np\n",
    "import os\n",
    "from random import shuffle # randomizing ordered data\n",
    "from tqdm import tqdm      # a nice pretty percentage bar for tasks.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# define variables \n",
    "\n",
    "IMG_WIDTH, IMG_HEIGHT = 100, 100 # dimensions of our images.\n",
    "source_dir_name = '/home/datascience/projects/vsoft/data/test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# One hot encoding of the target colum\n",
    "def label_img(img, word_label):\n",
    "    if word_label == 'Pepperoni': return [1,0]\n",
    "    elif word_label == 'Sausage': return [0,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create training data\n",
    "def create_train_data(directory='', label='', num_of_images=1000):\n",
    "    training_data = []\n",
    "    if directory=='':\n",
    "        directory = TRAIN_DIR\n",
    "    label_dir = directory+'/'+label\n",
    "    i=0\n",
    "    for img in tqdm(os.listdir(label_dir)):\n",
    "        img_label = label_img(img, label)\n",
    "        path = os.path.join(label_dir,img)\n",
    "        #img = cv2.imread(path,cv2.IMREAD_GRAYSCALE)\n",
    "        img = cv2.imread(path,cv2.IMREAD_COLOR)\n",
    "        #print(img.shape)\n",
    "        img = cv2.resize(img, (IMG_WIDTH, IMG_HEIGHT))\n",
    "        #print(img.shape)\n",
    "        training_data.append([np.array(img),np.array(img_label)])\n",
    "        i=i+1\n",
    "        if i>num_of_images:\n",
    "            break\n",
    "    #print(np.array(training_data).shape)\n",
    "    return training_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pepperoni_data_test = create_train_data(source_dir_name,'Pepperoni',10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sausage_data_test = create_train_data(source_dir_name,'Sausage',1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_data_unseen = np.concatenate((pepperoni_data_test, sausage_data_test), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_test_unseen = np.array([i[0] for i in test_data_unseen], dtype='f').reshape(-1, IMG_WIDTH, IMG_HEIGHT, 3)\n",
    "y_test_unseen = np.array([i[1] for i in test_data_unseen], dtype='int32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Predict the outcome of test data using model\n",
    "predictions_unseen = nn.predict(X_test_unseen, as_iterable=True)\n",
    "y_pred_unseen = []\n",
    "for i, p in enumerate(predictions_unseen):\n",
    "    y_pred_unseen.append(p['labels'])\n",
    "    print(\"Prediction %s: %s : %s\" % (i + 1, p['probs'], p['labels']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Predict accuracy score\n",
    "score = metrics.accuracy_score(np.argmax(y_test_unseen,1), y_pred_unseen)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
